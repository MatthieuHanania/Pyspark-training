{"cells":[{"cell_type":"markdown","source":["# Bike Rental DataSet from UCI Machine Learning Repository\n## Citations\nFanaee-T, Hadi, and Gama, Joao, 'Event labeling combining ensemble detectors and background knowledge', Progress in Artificial Intelligence (2013): pp. 1-15, Springer Berlin Heidelber\n## Attributes on original data\n\n\n- season : season (1:spring, 2:summer, 3:fall, 4:winter)\n- yr : year (0: 2011, 1:2012)\n- mnth : month ( 1 to 12)\n- hr : hour (0 to 23)\n- holiday : weather day is holiday or not (extracted from [Web Link])\n- weekday : day of the week\n- workingday : if day is neither weekend nor holiday is 1, otherwise is 0.\n- weathersit : \n - 1: Clear, Few clouds, Partly cloudy, Partly cloudy\n - 2: Mist + Cloudy, Mist + Broken clouds, Mist + Few clouds, Mist\n - 3: Light Snow, Light Rain + Thunderstorm + Scattered clouds, Light Rain + Scattered clouds\n - 4: Heavy Rain + Ice Pallets + Thunderstorm + Mist, Snow + Fog\n- temp : Normalized temperature in Celsius. The values are derived via (t-t_min)/(t_max-t_min), t_min=-8, t_max=+39 (only in hourly scale)\n- hum: Normalized humidity. The values are divided to 100 (max)\n- windspeed: Normalized wind speed. The values are divided to 67 (max)\n\n\n## URL:\nhttps://archive.ics.uci.edu/ml/datasets/Bike+Sharing+Dataset"],"metadata":{"application/vnd.databricks.v1+cell":{"showTitle":false,"cellMetadata":{},"nuid":"63d3d27a-922f-49e9-9525-fe10f41d14ab","inputWidgets":{},"title":""}}},{"cell_type":"code","source":["rowData = spark.read.csv(\"/FileStore/tables/Bike_Rental_UCI_dataset.csv\", inferSchema=True, header = True)"],"metadata":{"application/vnd.databricks.v1+cell":{"showTitle":false,"cellMetadata":{},"nuid":"555c3f36-a07e-4562-9684-f70c341ffce2","inputWidgets":{},"title":""}},"outputs":[],"execution_count":0},{"cell_type":"code","source":["rowData.show(n=5)"],"metadata":{"application/vnd.databricks.v1+cell":{"showTitle":false,"cellMetadata":{},"nuid":"7213bafc-4d01-4b3d-9aed-80deb4f9e1a7","inputWidgets":{},"title":""}},"outputs":[{"output_type":"stream","output_type":"stream","name":"stdout","text":["+------+---+----+---+-------+----------+----------+----+----+---------+---------+----+------+\n|season| yr|mnth| hr|holiday|workingday|weathersit|temp| hum|windspeed|dayOfWeek|days|demand|\n+------+---+----+---+-------+----------+----------+----+----+---------+---------+----+------+\n|     1|  0|   1|  0|      0|         0|         1|0.24|0.81|      0.0|      Sat|   0|    16|\n|     1|  0|   1|  1|      0|         0|         1|0.22| 0.8|      0.0|      Sat|   0|    40|\n|     1|  0|   1|  2|      0|         0|         1|0.22| 0.8|      0.0|      Sat|   0|    32|\n|     1|  0|   1|  3|      0|         0|         1|0.24|0.75|      0.0|      Sat|   0|    13|\n|     1|  0|   1|  4|      0|         0|         1|0.24|0.75|      0.0|      Sat|   0|     1|\n+------+---+----+---+-------+----------+----------+----+----+---------+---------+----+------+\nonly showing top 5 rows\n\n"]}],"execution_count":0},{"cell_type":"code","source":["rowData.printSchema()"],"metadata":{"application/vnd.databricks.v1+cell":{"showTitle":false,"cellMetadata":{},"nuid":"f454ed28-e4f9-4400-9e78-ed507d1e20b1","inputWidgets":{},"title":""}},"outputs":[{"output_type":"stream","output_type":"stream","name":"stdout","text":["root\n |-- season: integer (nullable = true)\n |-- yr: integer (nullable = true)\n |-- mnth: integer (nullable = true)\n |-- hr: integer (nullable = true)\n |-- holiday: integer (nullable = true)\n |-- workingday: integer (nullable = true)\n |-- weathersit: integer (nullable = true)\n |-- temp: double (nullable = true)\n |-- hum: double (nullable = true)\n |-- windspeed: double (nullable = true)\n |-- dayOfWeek: string (nullable = true)\n |-- days: integer (nullable = true)\n |-- demand: integer (nullable = true)\n\n"]}],"execution_count":0},{"cell_type":"code","source":["rowData.groupBy('dayOfWeek').count().show()"],"metadata":{"application/vnd.databricks.v1+cell":{"showTitle":false,"cellMetadata":{},"nuid":"8d4aa2db-1cfa-4a9e-891a-1b41e8b1e3d0","inputWidgets":{},"title":""}},"outputs":[{"output_type":"stream","output_type":"stream","name":"stdout","text":["+---------+-----+\n|dayOfWeek|count|\n+---------+-----+\n|      Sun| 2502|\n|      Mon| 2479|\n|      Sat| 2512|\n|      Wed| 2475|\n|      Tue| 2453|\n|      Fri| 2487|\n|      Thr| 2471|\n+---------+-----+\n\n"]}],"execution_count":0},{"cell_type":"code","source":["rowData.groupBy('mnth').count().show()"],"metadata":{"application/vnd.databricks.v1+cell":{"showTitle":false,"cellMetadata":{},"nuid":"a26ae496-04ce-4b4f-ae13-2cf7da8b2e83","inputWidgets":{},"title":""}},"outputs":[{"output_type":"stream","output_type":"stream","name":"stdout","text":["+----+-----+\n|mnth|count|\n+----+-----+\n|  12| 1483|\n|   1| 1429|\n|   6| 1440|\n|   3| 1473|\n|   5| 1488|\n|   9| 1437|\n|   4| 1437|\n|   8| 1475|\n|   7| 1488|\n|  10| 1451|\n|  11| 1437|\n|   2| 1341|\n+----+-----+\n\n"]}],"execution_count":0},{"cell_type":"code","source":["rowData.select(\"days\").distinct().count()"],"metadata":{"application/vnd.databricks.v1+cell":{"showTitle":false,"cellMetadata":{},"nuid":"71da1299-7349-41df-bcdd-7bb55b1cd793","inputWidgets":{},"title":""}},"outputs":[{"output_type":"stream","output_type":"stream","name":"stdout","text":["Out[6]: 725"]}],"execution_count":0},{"cell_type":"code","source":["rowData.groupBy('yr').count().show()"],"metadata":{"application/vnd.databricks.v1+cell":{"showTitle":false,"cellMetadata":{},"nuid":"e0a30e4f-2dbb-4f2f-88aa-b30661e36cf1","inputWidgets":{},"title":""}},"outputs":[{"output_type":"stream","output_type":"stream","name":"stdout","text":["+---+-----+\n| yr|count|\n+---+-----+\n|  1| 8734|\n|  0| 8645|\n+---+-----+\n\n"]}],"execution_count":0},{"cell_type":"code","source":["rowData.groupBy('season').count().show()"],"metadata":{"application/vnd.databricks.v1+cell":{"showTitle":false,"cellMetadata":{},"nuid":"92489e45-6bf9-41db-8109-ee5b762cddb7","inputWidgets":{},"title":""}},"outputs":[{"output_type":"stream","output_type":"stream","name":"stdout","text":["+------+-----+\n|season|count|\n+------+-----+\n|     1| 4242|\n|     3| 4496|\n|     4| 4232|\n|     2| 4409|\n+------+-----+\n\n"]}],"execution_count":0},{"cell_type":"code","source":["from pyspark.ml.feature import StringIndexer"],"metadata":{"application/vnd.databricks.v1+cell":{"showTitle":false,"cellMetadata":{},"nuid":"1cc4aeaf-4c9a-4935-bf9a-2171a8394332","inputWidgets":{},"title":""}},"outputs":[],"execution_count":0},{"cell_type":"code","source":["indexer = StringIndexer(inputCol='dayOfWeek', outputCol='day_cat')"],"metadata":{"application/vnd.databricks.v1+cell":{"showTitle":false,"cellMetadata":{},"nuid":"cc42d87f-d973-4e25-a252-1da9255b051b","inputWidgets":{},"title":""}},"outputs":[],"execution_count":0},{"cell_type":"code","source":["indexed_data =indexer.fit(rowData).transform(rowData)"],"metadata":{"application/vnd.databricks.v1+cell":{"showTitle":false,"cellMetadata":{},"nuid":"443faace-94f2-46e9-8a05-1ad70389742f","inputWidgets":{},"title":""}},"outputs":[],"execution_count":0},{"cell_type":"code","source":["indexed_data.show()"],"metadata":{"application/vnd.databricks.v1+cell":{"showTitle":false,"cellMetadata":{},"nuid":"fffd2e2f-3c8c-425b-bdfc-9cce1fee36b7","inputWidgets":{},"title":""}},"outputs":[{"output_type":"stream","output_type":"stream","name":"stdout","text":["+------+---+----+---+-------+----------+----------+----+----+---------+---------+----+------+-------+\n|season| yr|mnth| hr|holiday|workingday|weathersit|temp| hum|windspeed|dayOfWeek|days|demand|day_cat|\n+------+---+----+---+-------+----------+----------+----+----+---------+---------+----+------+-------+\n|     1|  0|   1|  0|      0|         0|         1|0.24|0.81|      0.0|      Sat|   0|    16|    0.0|\n|     1|  0|   1|  1|      0|         0|         1|0.22| 0.8|      0.0|      Sat|   0|    40|    0.0|\n|     1|  0|   1|  2|      0|         0|         1|0.22| 0.8|      0.0|      Sat|   0|    32|    0.0|\n|     1|  0|   1|  3|      0|         0|         1|0.24|0.75|      0.0|      Sat|   0|    13|    0.0|\n|     1|  0|   1|  4|      0|         0|         1|0.24|0.75|      0.0|      Sat|   0|     1|    0.0|\n|     1|  0|   1|  5|      0|         0|         2|0.24|0.75|   0.0896|      Sat|   0|     1|    0.0|\n|     1|  0|   1|  6|      0|         0|         1|0.22| 0.8|      0.0|      Sat|   0|     2|    0.0|\n|     1|  0|   1|  7|      0|         0|         1| 0.2|0.86|      0.0|      Sat|   0|     3|    0.0|\n|     1|  0|   1|  8|      0|         0|         1|0.24|0.75|      0.0|      Sat|   0|     8|    0.0|\n|     1|  0|   1|  9|      0|         0|         1|0.32|0.76|      0.0|      Sat|   0|    14|    0.0|\n|     1|  0|   1| 10|      0|         0|         1|0.38|0.76|   0.2537|      Sat|   0|    36|    0.0|\n|     1|  0|   1| 11|      0|         0|         1|0.36|0.81|   0.2836|      Sat|   0|    56|    0.0|\n|     1|  0|   1| 12|      0|         0|         1|0.42|0.77|   0.2836|      Sat|   0|    84|    0.0|\n|     1|  0|   1| 13|      0|         0|         2|0.46|0.72|   0.2985|      Sat|   0|    94|    0.0|\n|     1|  0|   1| 14|      0|         0|         2|0.46|0.72|   0.2836|      Sat|   0|   106|    0.0|\n|     1|  0|   1| 15|      0|         0|         2|0.44|0.77|   0.2985|      Sat|   0|   110|    0.0|\n|     1|  0|   1| 16|      0|         0|         2|0.42|0.82|   0.2985|      Sat|   0|    93|    0.0|\n|     1|  0|   1| 17|      0|         0|         2|0.44|0.82|   0.2836|      Sat|   0|    67|    0.0|\n|     1|  0|   1| 18|      0|         0|         3|0.42|0.88|   0.2537|      Sat|   0|    35|    0.0|\n|     1|  0|   1| 19|      0|         0|         3|0.42|0.88|   0.2537|      Sat|   0|    37|    0.0|\n+------+---+----+---+-------+----------+----------+----+----+---------+---------+----+------+-------+\nonly showing top 20 rows\n\n"]}],"execution_count":0},{"cell_type":"code","source":["indexed_data.select('day_cat').distinct().orderBy('day_cat').show()"],"metadata":{"application/vnd.databricks.v1+cell":{"showTitle":false,"cellMetadata":{},"nuid":"d2e3ebaf-4836-45cc-a612-07ec645e4e0c","inputWidgets":{},"title":""}},"outputs":[{"output_type":"stream","output_type":"stream","name":"stdout","text":["+-------+\n|day_cat|\n+-------+\n|    0.0|\n|    1.0|\n|    2.0|\n|    3.0|\n|    4.0|\n|    5.0|\n|    6.0|\n+-------+\n\n"]}],"execution_count":0},{"cell_type":"code","source":["indexed_data.groupBy('day_cat').count().orderBy('day_cat').show()"],"metadata":{"application/vnd.databricks.v1+cell":{"showTitle":false,"cellMetadata":{},"nuid":"70538dcd-9deb-42cc-a280-9250e4506f0f","inputWidgets":{},"title":""}},"outputs":[{"output_type":"stream","output_type":"stream","name":"stdout","text":["+-------+-----+\n|day_cat|count|\n+-------+-----+\n|    0.0| 2512|\n|    1.0| 2502|\n|    2.0| 2487|\n|    3.0| 2479|\n|    4.0| 2475|\n|    5.0| 2471|\n|    6.0| 2453|\n+-------+-----+\n\n"]}],"execution_count":0},{"cell_type":"code","source":["from pyspark.ml.regression import LinearRegression\nfrom pyspark.ml.feature import VectorAssembler"],"metadata":{"application/vnd.databricks.v1+cell":{"showTitle":false,"cellMetadata":{},"nuid":"872e4913-e651-4f48-89f4-9c83a137674b","inputWidgets":{},"title":""}},"outputs":[],"execution_count":0},{"cell_type":"code","source":["indexed_data.columns\n"],"metadata":{"application/vnd.databricks.v1+cell":{"showTitle":false,"cellMetadata":{},"nuid":"f160fc54-998d-4d1f-87e5-fade1768a6b3","inputWidgets":{},"title":""}},"outputs":[{"output_type":"stream","output_type":"stream","name":"stdout","text":["Out[16]: ['season',\n 'yr',\n 'mnth',\n 'hr',\n 'holiday',\n 'workingday',\n 'weathersit',\n 'temp',\n 'hum',\n 'windspeed',\n 'dayOfWeek',\n 'days',\n 'demand',\n 'day_cat']"]}],"execution_count":0},{"cell_type":"code","source":["vec = VectorAssembler(\n  inputCols= [\n    'season',\n    'yr',\n    'mnth',\n    'hr',\n    'holiday',\n    'workingday',\n    'weathersit',\n    'temp',\n    'hum',\n    'windspeed',\n    'day_cat'\n    ],\n   outputCol = 'features'                  \n )"],"metadata":{"application/vnd.databricks.v1+cell":{"showTitle":false,"cellMetadata":{},"nuid":"0401d9c2-2c62-4dbe-833c-d79c605a57f6","inputWidgets":{},"title":""}},"outputs":[],"execution_count":0},{"cell_type":"code","source":["data = vec.transform(indexed_data)"],"metadata":{"application/vnd.databricks.v1+cell":{"showTitle":false,"cellMetadata":{},"nuid":"be3f5cf3-fc69-482d-b687-c657b934642a","inputWidgets":{},"title":""}},"outputs":[],"execution_count":0},{"cell_type":"code","source":["data.show(truncate=False)"],"metadata":{"application/vnd.databricks.v1+cell":{"showTitle":false,"cellMetadata":{},"nuid":"4dde7f26-cc9a-40c4-8823-87b7cd01a30c","inputWidgets":{},"title":""}},"outputs":[{"output_type":"stream","output_type":"stream","name":"stdout","text":["+------+---+----+---+-------+----------+----------+----+----+---------+---------+----+------+-------+---------------------------------------------------+\n|season|yr |mnth|hr |holiday|workingday|weathersit|temp|hum |windspeed|dayOfWeek|days|demand|day_cat|features                                           |\n+------+---+----+---+-------+----------+----------+----+----+---------+---------+----+------+-------+---------------------------------------------------+\n|1     |0  |1   |0  |0      |0         |1         |0.24|0.81|0.0      |Sat      |0   |16    |0.0    |(11,[0,2,6,7,8],[1.0,1.0,1.0,0.24,0.81])           |\n|1     |0  |1   |1  |0      |0         |1         |0.22|0.8 |0.0      |Sat      |0   |40    |0.0    |(11,[0,2,3,6,7,8],[1.0,1.0,1.0,1.0,0.22,0.8])      |\n|1     |0  |1   |2  |0      |0         |1         |0.22|0.8 |0.0      |Sat      |0   |32    |0.0    |(11,[0,2,3,6,7,8],[1.0,1.0,2.0,1.0,0.22,0.8])      |\n|1     |0  |1   |3  |0      |0         |1         |0.24|0.75|0.0      |Sat      |0   |13    |0.0    |(11,[0,2,3,6,7,8],[1.0,1.0,3.0,1.0,0.24,0.75])     |\n|1     |0  |1   |4  |0      |0         |1         |0.24|0.75|0.0      |Sat      |0   |1     |0.0    |(11,[0,2,3,6,7,8],[1.0,1.0,4.0,1.0,0.24,0.75])     |\n|1     |0  |1   |5  |0      |0         |2         |0.24|0.75|0.0896   |Sat      |0   |1     |0.0    |[1.0,0.0,1.0,5.0,0.0,0.0,2.0,0.24,0.75,0.0896,0.0] |\n|1     |0  |1   |6  |0      |0         |1         |0.22|0.8 |0.0      |Sat      |0   |2     |0.0    |(11,[0,2,3,6,7,8],[1.0,1.0,6.0,1.0,0.22,0.8])      |\n|1     |0  |1   |7  |0      |0         |1         |0.2 |0.86|0.0      |Sat      |0   |3     |0.0    |(11,[0,2,3,6,7,8],[1.0,1.0,7.0,1.0,0.2,0.86])      |\n|1     |0  |1   |8  |0      |0         |1         |0.24|0.75|0.0      |Sat      |0   |8     |0.0    |(11,[0,2,3,6,7,8],[1.0,1.0,8.0,1.0,0.24,0.75])     |\n|1     |0  |1   |9  |0      |0         |1         |0.32|0.76|0.0      |Sat      |0   |14    |0.0    |(11,[0,2,3,6,7,8],[1.0,1.0,9.0,1.0,0.32,0.76])     |\n|1     |0  |1   |10 |0      |0         |1         |0.38|0.76|0.2537   |Sat      |0   |36    |0.0    |[1.0,0.0,1.0,10.0,0.0,0.0,1.0,0.38,0.76,0.2537,0.0]|\n|1     |0  |1   |11 |0      |0         |1         |0.36|0.81|0.2836   |Sat      |0   |56    |0.0    |[1.0,0.0,1.0,11.0,0.0,0.0,1.0,0.36,0.81,0.2836,0.0]|\n|1     |0  |1   |12 |0      |0         |1         |0.42|0.77|0.2836   |Sat      |0   |84    |0.0    |[1.0,0.0,1.0,12.0,0.0,0.0,1.0,0.42,0.77,0.2836,0.0]|\n|1     |0  |1   |13 |0      |0         |2         |0.46|0.72|0.2985   |Sat      |0   |94    |0.0    |[1.0,0.0,1.0,13.0,0.0,0.0,2.0,0.46,0.72,0.2985,0.0]|\n|1     |0  |1   |14 |0      |0         |2         |0.46|0.72|0.2836   |Sat      |0   |106   |0.0    |[1.0,0.0,1.0,14.0,0.0,0.0,2.0,0.46,0.72,0.2836,0.0]|\n|1     |0  |1   |15 |0      |0         |2         |0.44|0.77|0.2985   |Sat      |0   |110   |0.0    |[1.0,0.0,1.0,15.0,0.0,0.0,2.0,0.44,0.77,0.2985,0.0]|\n|1     |0  |1   |16 |0      |0         |2         |0.42|0.82|0.2985   |Sat      |0   |93    |0.0    |[1.0,0.0,1.0,16.0,0.0,0.0,2.0,0.42,0.82,0.2985,0.0]|\n|1     |0  |1   |17 |0      |0         |2         |0.44|0.82|0.2836   |Sat      |0   |67    |0.0    |[1.0,0.0,1.0,17.0,0.0,0.0,2.0,0.44,0.82,0.2836,0.0]|\n|1     |0  |1   |18 |0      |0         |3         |0.42|0.88|0.2537   |Sat      |0   |35    |0.0    |[1.0,0.0,1.0,18.0,0.0,0.0,3.0,0.42,0.88,0.2537,0.0]|\n|1     |0  |1   |19 |0      |0         |3         |0.42|0.88|0.2537   |Sat      |0   |37    |0.0    |[1.0,0.0,1.0,19.0,0.0,0.0,3.0,0.42,0.88,0.2537,0.0]|\n+------+---+----+---+-------+----------+----------+----+----+---------+---------+----+------+-------+---------------------------------------------------+\nonly showing top 20 rows\n\n"]}],"execution_count":0},{"cell_type":"code","source":["data.take(1)"],"metadata":{"application/vnd.databricks.v1+cell":{"showTitle":false,"cellMetadata":{},"nuid":"79431cf1-05e4-4104-b41a-56895265a322","inputWidgets":{},"title":""}},"outputs":[{"output_type":"stream","output_type":"stream","name":"stdout","text":["Out[20]: [Row(season=1, yr=0, mnth=1, hr=0, holiday=0, workingday=0, weathersit=1, temp=0.24, hum=0.81, windspeed=0.0, dayOfWeek='Sat', days=0, demand=16, day_cat=0.0, features=SparseVector(11, {0: 1.0, 2: 1.0, 6: 1.0, 7: 0.24, 8: 0.81}))]"]}],"execution_count":0},{"cell_type":"code","source":["for item in data.take(1)[0]:\n    print (item)"],"metadata":{"application/vnd.databricks.v1+cell":{"showTitle":false,"cellMetadata":{},"nuid":"44888bc7-c1b5-436a-afe7-4ac8336688f7","inputWidgets":{},"title":""}},"outputs":[{"output_type":"stream","output_type":"stream","name":"stdout","text":["1\n0\n1\n0\n0\n0\n1\n0.24\n0.81\n0.0\nSat\n0\n16\n0.0\n(11,[0,2,6,7,8],[1.0,1.0,1.0,0.24,0.81])\n"]}],"execution_count":0},{"cell_type":"code","source":["for item in data.take(3):\n  print (item)\n  print('\\n')"],"metadata":{"application/vnd.databricks.v1+cell":{"showTitle":false,"cellMetadata":{},"nuid":"d437f598-bf23-4df7-8ec8-d57ad8b8e995","inputWidgets":{},"title":""}},"outputs":[{"output_type":"stream","output_type":"stream","name":"stdout","text":["Row(season=1, yr=0, mnth=1, hr=0, holiday=0, workingday=0, weathersit=1, temp=0.24, hum=0.81, windspeed=0.0, dayOfWeek='Sat', days=0, demand=16, day_cat=0.0, features=SparseVector(11, {0: 1.0, 2: 1.0, 6: 1.0, 7: 0.24, 8: 0.81}))\n\n\nRow(season=1, yr=0, mnth=1, hr=1, holiday=0, workingday=0, weathersit=1, temp=0.22, hum=0.8, windspeed=0.0, dayOfWeek='Sat', days=0, demand=40, day_cat=0.0, features=SparseVector(11, {0: 1.0, 2: 1.0, 3: 1.0, 6: 1.0, 7: 0.22, 8: 0.8}))\n\n\nRow(season=1, yr=0, mnth=1, hr=2, holiday=0, workingday=0, weathersit=1, temp=0.22, hum=0.8, windspeed=0.0, dayOfWeek='Sat', days=0, demand=32, day_cat=0.0, features=SparseVector(11, {0: 1.0, 2: 1.0, 3: 2.0, 6: 1.0, 7: 0.22, 8: 0.8}))\n\n\n"]}],"execution_count":0},{"cell_type":"code","source":["modelData = data.select('features', 'demand') "],"metadata":{"application/vnd.databricks.v1+cell":{"showTitle":false,"cellMetadata":{},"nuid":"aeffd165-ce61-4562-8fc0-d544b7ad4789","inputWidgets":{},"title":""}},"outputs":[],"execution_count":0},{"cell_type":"code","source":["modelData.show(truncate =False)"],"metadata":{"application/vnd.databricks.v1+cell":{"showTitle":false,"cellMetadata":{},"nuid":"5aaf1cbc-9b82-499f-977c-572c161b0631","inputWidgets":{},"title":""}},"outputs":[{"output_type":"stream","output_type":"stream","name":"stdout","text":["+---------------------------------------------------+------+\n|features                                           |demand|\n+---------------------------------------------------+------+\n|(11,[0,2,6,7,8],[1.0,1.0,1.0,0.24,0.81])           |16    |\n|(11,[0,2,3,6,7,8],[1.0,1.0,1.0,1.0,0.22,0.8])      |40    |\n|(11,[0,2,3,6,7,8],[1.0,1.0,2.0,1.0,0.22,0.8])      |32    |\n|(11,[0,2,3,6,7,8],[1.0,1.0,3.0,1.0,0.24,0.75])     |13    |\n|(11,[0,2,3,6,7,8],[1.0,1.0,4.0,1.0,0.24,0.75])     |1     |\n|[1.0,0.0,1.0,5.0,0.0,0.0,2.0,0.24,0.75,0.0896,0.0] |1     |\n|(11,[0,2,3,6,7,8],[1.0,1.0,6.0,1.0,0.22,0.8])      |2     |\n|(11,[0,2,3,6,7,8],[1.0,1.0,7.0,1.0,0.2,0.86])      |3     |\n|(11,[0,2,3,6,7,8],[1.0,1.0,8.0,1.0,0.24,0.75])     |8     |\n|(11,[0,2,3,6,7,8],[1.0,1.0,9.0,1.0,0.32,0.76])     |14    |\n|[1.0,0.0,1.0,10.0,0.0,0.0,1.0,0.38,0.76,0.2537,0.0]|36    |\n|[1.0,0.0,1.0,11.0,0.0,0.0,1.0,0.36,0.81,0.2836,0.0]|56    |\n|[1.0,0.0,1.0,12.0,0.0,0.0,1.0,0.42,0.77,0.2836,0.0]|84    |\n|[1.0,0.0,1.0,13.0,0.0,0.0,2.0,0.46,0.72,0.2985,0.0]|94    |\n|[1.0,0.0,1.0,14.0,0.0,0.0,2.0,0.46,0.72,0.2836,0.0]|106   |\n|[1.0,0.0,1.0,15.0,0.0,0.0,2.0,0.44,0.77,0.2985,0.0]|110   |\n|[1.0,0.0,1.0,16.0,0.0,0.0,2.0,0.42,0.82,0.2985,0.0]|93    |\n|[1.0,0.0,1.0,17.0,0.0,0.0,2.0,0.44,0.82,0.2836,0.0]|67    |\n|[1.0,0.0,1.0,18.0,0.0,0.0,3.0,0.42,0.88,0.2537,0.0]|35    |\n|[1.0,0.0,1.0,19.0,0.0,0.0,3.0,0.42,0.88,0.2537,0.0]|37    |\n+---------------------------------------------------+------+\nonly showing top 20 rows\n\n"]}],"execution_count":0},{"cell_type":"code","source":["trainData, testData = modelData.randomSplit([0.7, 0.3])"],"metadata":{"application/vnd.databricks.v1+cell":{"showTitle":false,"cellMetadata":{},"nuid":"a328708d-db8f-4f5c-b7a8-e3d1aee1a8f1","inputWidgets":{},"title":""}},"outputs":[],"execution_count":0},{"cell_type":"code","source":["modelData.describe().show()"],"metadata":{"application/vnd.databricks.v1+cell":{"showTitle":false,"cellMetadata":{},"nuid":"81134826-9cb3-4dfc-a132-edb5a246a37f","inputWidgets":{},"title":""}},"outputs":[{"output_type":"stream","output_type":"stream","name":"stdout","text":["+-------+------------------+\n|summary|            demand|\n+-------+------------------+\n|  count|             17379|\n|   mean|189.46308763450142|\n| stddev| 181.3875990918646|\n|    min|                 1|\n|    max|               977|\n+-------+------------------+\n\n"]}],"execution_count":0},{"cell_type":"code","source":["trainData.describe().show()"],"metadata":{"application/vnd.databricks.v1+cell":{"showTitle":false,"cellMetadata":{},"nuid":"8e70c31a-87b8-43af-8d38-d25cdc728e8f","inputWidgets":{},"title":""}},"outputs":[{"output_type":"stream","output_type":"stream","name":"stdout","text":["+-------+------------------+\n|summary|            demand|\n+-------+------------------+\n|  count|             12143|\n|   mean|189.95882401383514|\n| stddev|182.09510526251742|\n|    min|                 1|\n|    max|               977|\n+-------+------------------+\n\n"]}],"execution_count":0},{"cell_type":"code","source":["testData.describe().show()"],"metadata":{"application/vnd.databricks.v1+cell":{"showTitle":false,"cellMetadata":{},"nuid":"2d171535-563f-4475-a4dd-944186d230db","inputWidgets":{},"title":""}},"outputs":[{"output_type":"stream","output_type":"stream","name":"stdout","text":["+-------+------------------+\n|summary|            demand|\n+-------+------------------+\n|  count|              5236|\n|   mean|188.31340718105423|\n| stddev|179.74811660987626|\n|    min|                 1|\n|    max|               976|\n+-------+------------------+\n\n"]}],"execution_count":0},{"cell_type":"code","source":["help(LinearRegression)"],"metadata":{"application/vnd.databricks.v1+cell":{"showTitle":false,"cellMetadata":{},"nuid":"00debd6d-a76b-4c0d-9fac-8a49afcda371","inputWidgets":{},"title":""}},"outputs":[{"output_type":"stream","output_type":"stream","name":"stdout","text":["Help on class LinearRegression in module pyspark.ml.regression:\n\nclass LinearRegression(_JavaRegressor, _LinearRegressionParams, pyspark.ml.util.JavaMLWritable, pyspark.ml.util.JavaMLReadable)\n |  LinearRegression(*, featuresCol: str = 'features', labelCol: str = 'label', predictionCol: str = 'prediction', maxIter: int = 100, regParam: float = 0.0, elasticNetParam: float = 0.0, tol: float = 1e-06, fitIntercept: bool = True, standardization: bool = True, solver: str = 'auto', weightCol: Optional[str] = None, aggregationDepth: int = 2, loss: str = 'squaredError', epsilon: float = 1.35, maxBlockSizeInMB: float = 0.0)\n |  \n |  Linear regression.\n |  \n |  The learning objective is to minimize the specified loss function, with regularization.\n |  This supports two kinds of loss:\n |  \n |  * squaredError (a.k.a squared loss)\n |  * huber (a hybrid of squared error for relatively small errors and absolute error for     relatively large ones, and we estimate the scale parameter from training data)\n |  \n |  This supports multiple types of regularization:\n |  \n |  * none (a.k.a. ordinary least squares)\n |  * L2 (ridge regression)\n |  * L1 (Lasso)\n |  * L2 + L1 (elastic net)\n |  \n |  .. versionadded:: 1.4.0\n |  \n |  Notes\n |  -----\n |  Fitting with huber loss only supports none and L2 regularization.\n |  \n |  Examples\n |  --------\n |  >>> from pyspark.ml.linalg import Vectors\n |  >>> df = spark.createDataFrame([\n |  ...     (1.0, 2.0, Vectors.dense(1.0)),\n |  ...     (0.0, 2.0, Vectors.sparse(1, [], []))], [\"label\", \"weight\", \"features\"])\n |  >>> lr = LinearRegression(regParam=0.0, solver=\"normal\", weightCol=\"weight\")\n |  >>> lr.setMaxIter(5)\n |  LinearRegression...\n |  >>> lr.getMaxIter()\n |  5\n |  >>> lr.setRegParam(0.1)\n |  LinearRegression...\n |  >>> lr.getRegParam()\n |  0.1\n |  >>> lr.setRegParam(0.0)\n |  LinearRegression...\n |  >>> model = lr.fit(df)\n |  >>> model.setFeaturesCol(\"features\")\n |  LinearRegressionModel...\n |  >>> model.setPredictionCol(\"newPrediction\")\n |  LinearRegressionModel...\n |  >>> model.getMaxIter()\n |  5\n |  >>> model.getMaxBlockSizeInMB()\n |  0.0\n |  >>> test0 = spark.createDataFrame([(Vectors.dense(-1.0),)], [\"features\"])\n |  >>> abs(model.predict(test0.head().features) - (-1.0)) < 0.001\n |  True\n |  >>> abs(model.transform(test0).head().newPrediction - (-1.0)) < 0.001\n |  True\n |  >>> abs(model.coefficients[0] - 1.0) < 0.001\n |  True\n |  >>> abs(model.intercept - 0.0) < 0.001\n |  True\n |  >>> test1 = spark.createDataFrame([(Vectors.sparse(1, [0], [1.0]),)], [\"features\"])\n |  >>> abs(model.transform(test1).head().newPrediction - 1.0) < 0.001\n |  True\n |  >>> lr.setParams(featuresCol=\"vector\")\n |  LinearRegression...\n |  >>> lr_path = temp_path + \"/lr\"\n |  >>> lr.save(lr_path)\n |  >>> lr2 = LinearRegression.load(lr_path)\n |  >>> lr2.getMaxIter()\n |  5\n |  >>> model_path = temp_path + \"/lr_model\"\n |  >>> model.save(model_path)\n |  >>> model2 = LinearRegressionModel.load(model_path)\n |  >>> model.coefficients[0] == model2.coefficients[0]\n |  True\n |  >>> model.intercept == model2.intercept\n |  True\n |  >>> model.transform(test0).take(1) == model2.transform(test0).take(1)\n |  True\n |  >>> model.numFeatures\n |  1\n |  >>> model.write().format(\"pmml\").save(model_path + \"_2\")\n |  \n |  Method resolution order:\n |      LinearRegression\n |      _JavaRegressor\n |      Regressor\n |      pyspark.ml.wrapper.JavaPredictor\n |      pyspark.ml.base.Predictor\n |      pyspark.ml.wrapper.JavaEstimator\n |      pyspark.ml.wrapper.JavaParams\n |      pyspark.ml.wrapper.JavaWrapper\n |      pyspark.ml.base.Estimator\n |      _LinearRegressionParams\n |      pyspark.ml.base._PredictorParams\n |      pyspark.ml.param.shared.HasLabelCol\n |      pyspark.ml.param.shared.HasFeaturesCol\n |      pyspark.ml.param.shared.HasPredictionCol\n |      pyspark.ml.param.shared.HasRegParam\n |      pyspark.ml.param.shared.HasElasticNetParam\n |      pyspark.ml.param.shared.HasMaxIter\n |      pyspark.ml.param.shared.HasTol\n |      pyspark.ml.param.shared.HasFitIntercept\n |      pyspark.ml.param.shared.HasStandardization\n |      pyspark.ml.param.shared.HasWeightCol\n |      pyspark.ml.param.shared.HasSolver\n |      pyspark.ml.param.shared.HasAggregationDepth\n |      pyspark.ml.param.shared.HasLoss\n |      pyspark.ml.param.shared.HasMaxBlockSizeInMB\n |      pyspark.ml.param.Params\n |      pyspark.ml.util.Identifiable\n |      pyspark.ml.util.JavaMLWritable\n |      pyspark.ml.util.MLWritable\n |      pyspark.ml.util.JavaMLReadable\n |      pyspark.ml.util.MLReadable\n |      typing.Generic\n |      builtins.object\n |  \n |  Methods defined here:\n |  \n |  __init__(self, *, featuresCol: str = 'features', labelCol: str = 'label', predictionCol: str = 'prediction', maxIter: int = 100, regParam: float = 0.0, elasticNetParam: float = 0.0, tol: float = 1e-06, fitIntercept: bool = True, standardization: bool = True, solver: str = 'auto', weightCol: Optional[str] = None, aggregationDepth: int = 2, loss: str = 'squaredError', epsilon: float = 1.35, maxBlockSizeInMB: float = 0.0)\n |      __init__(self, \\*, featuresCol=\"features\", labelCol=\"label\", predictionCol=\"prediction\",                  maxIter=100, regParam=0.0, elasticNetParam=0.0, tol=1e-6, fitIntercept=True,                  standardization=True, solver=\"auto\", weightCol=None, aggregationDepth=2,                  loss=\"squaredError\", epsilon=1.35, maxBlockSizeInMB=0.0)\n |  \n |  setAggregationDepth(self, value: int) -> 'LinearRegression'\n |      Sets the value of :py:attr:`aggregationDepth`.\n |  \n |  setElasticNetParam(self, value: float) -> 'LinearRegression'\n |      Sets the value of :py:attr:`elasticNetParam`.\n |  \n |  setEpsilon(self, value: float) -> 'LinearRegression'\n |      Sets the value of :py:attr:`epsilon`.\n |      \n |      .. versionadded:: 2.3.0\n |  \n |  setFitIntercept(self, value: bool) -> 'LinearRegression'\n |      Sets the value of :py:attr:`fitIntercept`.\n |  \n |  setLoss(self, value: str) -> 'LinearRegression'\n |      Sets the value of :py:attr:`loss`.\n |  \n |  setMaxBlockSizeInMB(self, value: float) -> 'LinearRegression'\n |      Sets the value of :py:attr:`maxBlockSizeInMB`.\n |      \n |      .. versionadded:: 3.1.0\n |  \n |  setMaxIter(self, value: int) -> 'LinearRegression'\n |      Sets the value of :py:attr:`maxIter`.\n |  \n |  setParams(self, *, featuresCol: str = 'features', labelCol: str = 'label', predictionCol: str = 'prediction', maxIter: int = 100, regParam: float = 0.0, elasticNetParam: float = 0.0, tol: float = 1e-06, fitIntercept: bool = True, standardization: bool = True, solver: str = 'auto', weightCol: Optional[str] = None, aggregationDepth: int = 2, loss: str = 'squaredError', epsilon: float = 1.35, maxBlockSizeInMB: float = 0.0) -> 'LinearRegression'\n |      setParams(self, \\*, featuresCol=\"features\", labelCol=\"label\", predictionCol=\"prediction\",                   maxIter=100, regParam=0.0, elasticNetParam=0.0, tol=1e-6, fitIntercept=True,                   standardization=True, solver=\"auto\", weightCol=None, aggregationDepth=2,                   loss=\"squaredError\", epsilon=1.35, maxBlockSizeInMB=0.0)\n |      Sets params for linear regression.\n |      \n |      .. versionadded:: 1.4.0\n |  \n |  setRegParam(self, value: float) -> 'LinearRegression'\n |      Sets the value of :py:attr:`regParam`.\n |  \n |  setSolver(self, value: str) -> 'LinearRegression'\n |      Sets the value of :py:attr:`solver`.\n |  \n |  setStandardization(self, value: bool) -> 'LinearRegression'\n |      Sets the value of :py:attr:`standardization`.\n |  \n |  setTol(self, value: float) -> 'LinearRegression'\n |      Sets the value of :py:attr:`tol`.\n |  \n |  setWeightCol(self, value: str) -> 'LinearRegression'\n |      Sets the value of :py:attr:`weightCol`.\n |  \n |  ----------------------------------------------------------------------\n |  Data and other attributes defined here:\n |  \n |  __abstractmethods__ = frozenset()\n |  \n |  __annotations__ = {'_input_kwargs': typing.Dict[str, typing.Any]}\n |  \n |  __orig_bases__ = (pyspark.ml.regression._JavaRegressor[ForwardRef('Lin...\n |  \n |  __parameters__ = ()\n |  \n |  ----------------------------------------------------------------------\n |  Methods inherited from pyspark.ml.base.Predictor:\n |  \n |  setFeaturesCol(self: ~P, value: str) -> ~P\n |      Sets the value of :py:attr:`featuresCol`.\n |      \n |      .. versionadded:: 3.0.0\n |  \n |  setLabelCol(self: ~P, value: str) -> ~P\n |      Sets the value of :py:attr:`labelCol`.\n |      \n |      .. versionadded:: 3.0.0\n |  \n |  setPredictionCol(self: ~P, value: str) -> ~P\n |      Sets the value of :py:attr:`predictionCol`.\n |      \n |      .. versionadded:: 3.0.0\n |  \n |  ----------------------------------------------------------------------\n |  Methods inherited from pyspark.ml.wrapper.JavaParams:\n |  \n |  clear(self, param: pyspark.ml.param.Param) -> None\n |      Clears a param from the param map if it has been explicitly set.\n |  \n |  copy(self: 'JP', extra: Optional[ForwardRef('ParamMap')] = None) -> 'JP'\n |      Creates a copy of this instance with the same uid and some\n |      extra params. This implementation first calls Params.copy and\n |      then make a copy of the companion Java pipeline component with\n |      extra params. So both the Python wrapper and the Java pipeline\n |      component get copied.\n |      \n |      Parameters\n |      ----------\n |      extra : dict, optional\n |          Extra parameters to copy to the new instance\n |      \n |      Returns\n |      -------\n |      :py:class:`JavaParams`\n |          Copy of this instance\n |  \n |  ----------------------------------------------------------------------\n |  Methods inherited from pyspark.ml.wrapper.JavaWrapper:\n |  \n |  __del__(self) -> None\n |  \n |  ----------------------------------------------------------------------\n |  Data descriptors inherited from pyspark.ml.wrapper.JavaWrapper:\n |  \n |  __dict__\n |      dictionary for instance variables (if defined)\n |  \n |  __weakref__\n |      list of weak references to the object (if defined)\n |  \n |  ----------------------------------------------------------------------\n |  Methods inherited from pyspark.ml.base.Estimator:\n |  \n |  fit(self, dataset: pyspark.sql.dataframe.DataFrame, params: Union[ForwardRef('ParamMap'), List[ForwardRef('ParamMap')], Tuple[ForwardRef('ParamMap')], NoneType] = None) -> Union[~M, List[~M]]\n |      Fits a model to the input dataset with optional parameters.\n |      \n |      .. versionadded:: 1.3.0\n |      \n |      Parameters\n |      ----------\n |      dataset : :py:class:`pyspark.sql.DataFrame`\n |          input dataset.\n |      params : dict or list or tuple, optional\n |          an optional param map that overrides embedded params. If a list/tuple of\n |          param maps is given, this calls fit on each param map and returns a list of\n |          models.\n |      \n |      Returns\n |      -------\n |      :py:class:`Transformer` or a list of :py:class:`Transformer`\n |          fitted model(s)\n |  \n |  fitMultiple(self, dataset: pyspark.sql.dataframe.DataFrame, paramMaps: Sequence[ForwardRef('ParamMap')]) -> Iterator[Tuple[int, ~M]]\n |      Fits a model to the input dataset for each param map in `paramMaps`.\n |      \n |      .. versionadded:: 2.3.0\n |      \n |      Parameters\n |      ----------\n |      dataset : :py:class:`pyspark.sql.DataFrame`\n |          input dataset.\n |      paramMaps : :py:class:`collections.abc.Sequence`\n |          A Sequence of param maps.\n |      \n |      Returns\n |      -------\n |      :py:class:`_FitMultipleIterator`\n |          A thread safe iterable which contains one model for each param map. Each\n |          call to `next(modelIterator)` will return `(index, model)` where model was fit\n |          using `paramMaps[index]`. `index` values may not be sequential.\n |  \n |  ----------------------------------------------------------------------\n |  Methods inherited from _LinearRegressionParams:\n |  \n |  getEpsilon(self) -> float\n |      Gets the value of epsilon or its default value.\n |      \n |      .. versionadded:: 2.3.0\n |  \n |  ----------------------------------------------------------------------\n |  Data and other attributes inherited from _LinearRegressionParams:\n |  \n |  epsilon = Param(parent='undefined', name='epsilon', doc='T...s. Must b...\n |  \n |  loss = Param(parent='undefined', name='loss', doc='The ...imized. Supp...\n |  \n |  solver = Param(parent='undefined', name='solver', doc='Th...ation. Sup...\n |  \n |  ----------------------------------------------------------------------\n |  Methods inherited from pyspark.ml.param.shared.HasLabelCol:\n |  \n |  getLabelCol(self) -> str\n |      Gets the value of labelCol or its default value.\n |  \n |  ----------------------------------------------------------------------\n |  Data and other attributes inherited from pyspark.ml.param.shared.HasLabelCol:\n |  \n |  labelCol = Param(parent='undefined', name='labelCol', doc='label colum...\n |  \n |  ----------------------------------------------------------------------\n |  Methods inherited from pyspark.ml.param.shared.HasFeaturesCol:\n |  \n |  getFeaturesCol(self) -> str\n |      Gets the value of featuresCol or its default value.\n |  \n |  ----------------------------------------------------------------------\n |  Data and other attributes inherited from pyspark.ml.param.shared.HasFeaturesCol:\n |  \n |  featuresCol = Param(parent='undefined', name='featuresCol', doc='featu...\n |  \n |  ----------------------------------------------------------------------\n |  Methods inherited from pyspark.ml.param.shared.HasPredictionCol:\n |  \n |  getPredictionCol(self) -> str\n |      Gets the value of predictionCol or its default value.\n |  \n |  ----------------------------------------------------------------------\n |  Data and other attributes inherited from pyspark.ml.param.shared.HasPredictionCol:\n |  \n |  predictionCol = Param(parent='undefined', name='predictionCol', doc='p...\n |  \n |  ----------------------------------------------------------------------\n |  Methods inherited from pyspark.ml.param.shared.HasRegParam:\n |  \n |  getRegParam(self) -> float\n |      Gets the value of regParam or its default value.\n |  \n |  ----------------------------------------------------------------------\n |  Data and other attributes inherited from pyspark.ml.param.shared.HasRegParam:\n |  \n |  regParam = Param(parent='undefined', name='regParam', doc='regularizat...\n |  \n |  ----------------------------------------------------------------------\n |  Methods inherited from pyspark.ml.param.shared.HasElasticNetParam:\n |  \n |  getElasticNetParam(self) -> float\n |      Gets the value of elasticNetParam or its default value.\n |  \n |  ----------------------------------------------------------------------\n |  Data and other attributes inherited from pyspark.ml.param.shared.HasElasticNetParam:\n |  \n |  elasticNetParam = Param(parent='undefined', name='elasticNetParam'...L...\n |  \n |  ----------------------------------------------------------------------\n |  Methods inherited from pyspark.ml.param.shared.HasMaxIter:\n |  \n |  getMaxIter(self) -> int\n |      Gets the value of maxIter or its default value.\n |  \n |  ----------------------------------------------------------------------\n |  Data and other attributes inherited from pyspark.ml.param.shared.HasMaxIter:\n |  \n |  maxIter = Param(parent='undefined', name='maxIter', doc='max number of...\n |  \n |  ----------------------------------------------------------------------\n |  Methods inherited from pyspark.ml.param.shared.HasTol:\n |  \n |  getTol(self) -> float\n |      Gets the value of tol or its default value.\n |  \n |  ----------------------------------------------------------------------\n |  Data and other attributes inherited from pyspark.ml.param.shared.HasTol:\n |  \n |  tol = Param(parent='undefined', name='tol', doc='the c...ence toleranc...\n |  \n |  ----------------------------------------------------------------------\n |  Methods inherited from pyspark.ml.param.shared.HasFitIntercept:\n |  \n |  getFitIntercept(self) -> bool\n |      Gets the value of fitIntercept or its default value.\n |  \n |  ----------------------------------------------------------------------\n |  Data and other attributes inherited from pyspark.ml.param.shared.HasFitIntercept:\n |  \n |  fitIntercept = Param(parent='undefined', name='fitIntercept', doc='whe...\n |  \n |  ----------------------------------------------------------------------\n |  Methods inherited from pyspark.ml.param.shared.HasStandardization:\n |  \n |  getStandardization(self) -> bool\n |      Gets the value of standardization or its default value.\n |  \n |  ----------------------------------------------------------------------\n |  Data and other attributes inherited from pyspark.ml.param.shared.HasStandardization:\n |  \n |  standardization = Param(parent='undefined', name='standardization'...t...\n |  \n |  ----------------------------------------------------------------------\n |  Methods inherited from pyspark.ml.param.shared.HasWeightCol:\n |  \n |  getWeightCol(self) -> str\n |      Gets the value of weightCol or its default value.\n |  \n |  ----------------------------------------------------------------------\n |  Data and other attributes inherited from pyspark.ml.param.shared.HasWeightCol:\n |  \n |  weightCol = Param(parent='undefined', name='weightCol', doc=...or empt...\n |  \n |  ----------------------------------------------------------------------\n |  Methods inherited from pyspark.ml.param.shared.HasSolver:\n |  \n |  getSolver(self) -> str\n |      Gets the value of solver or its default value.\n |  \n |  ----------------------------------------------------------------------\n |  Methods inherited from pyspark.ml.param.shared.HasAggregationDepth:\n |  \n |  getAggregationDepth(self) -> int\n |      Gets the value of aggregationDepth or its default value.\n |  \n |  ----------------------------------------------------------------------\n |  Data and other attributes inherited from pyspark.ml.param.shared.HasAggregationDepth:\n |  \n |  aggregationDepth = Param(parent='undefined', name='aggregationDepth', ...\n |  \n |  ----------------------------------------------------------------------\n |  Methods inherited from pyspark.ml.param.shared.HasLoss:\n |  \n |  getLoss(self) -> str\n |      Gets the value of loss or its default value.\n |  \n |  ----------------------------------------------------------------------\n |  Methods inherited from pyspark.ml.param.shared.HasMaxBlockSizeInMB:\n |  \n |  getMaxBlockSizeInMB(self) -> float\n |      Gets the value of maxBlockSizeInMB or its default value.\n |  \n |  ----------------------------------------------------------------------\n |  Data and other attributes inherited from pyspark.ml.param.shared.HasMaxBlockSizeInMB:\n |  \n |  maxBlockSizeInMB = Param(parent='undefined', name='maxBlockSizeInMB......\n |  \n |  ----------------------------------------------------------------------\n |  Methods inherited from pyspark.ml.param.Params:\n |  \n |  explainParam(self, param: Union[str, pyspark.ml.param.Param]) -> str\n |      Explains a single param and returns its name, doc, and optional\n |      default value and user-supplied value in a string.\n |  \n |  explainParams(self) -> str\n |      Returns the documentation of all params with their optionally\n |      default values and user-supplied values.\n |  \n |  extractParamMap(self, extra: Optional[ForwardRef('ParamMap')] = None) -> 'ParamMap'\n |      Extracts the embedded default param values and user-supplied\n |      values, and then merges them with extra values from input into\n |      a flat param map, where the latter value is used if there exist\n |      conflicts, i.e., with ordering: default param values <\n |      user-supplied values < extra.\n |      \n |      Parameters\n |      ----------\n |      extra : dict, optional\n |          extra param values\n |      \n |      Returns\n |      -------\n |      dict\n |          merged param map\n |  \n |  getOrDefault(self, param: Union[str, pyspark.ml.param.Param[~T]]) -> Union[Any, ~T]\n |      Gets the value of a param in the user-supplied param map or its\n |      default value. Raises an error if neither is set.\n |  \n |  getParam(self, paramName: str) -> pyspark.ml.param.Param\n |      Gets a param by its name.\n |  \n |  hasDefault(self, param: Union[str, pyspark.ml.param.Param[Any]]) -> bool\n |      Checks whether a param has a default value.\n |  \n |  hasParam(self, paramName: str) -> bool\n |      Tests whether this instance contains a param with a given\n |      (string) name.\n |  \n |  isDefined(self, param: Union[str, pyspark.ml.param.Param[Any]]) -> bool\n |      Checks whether a param is explicitly set by user or has\n |      a default value.\n |  \n |  isSet(self, param: Union[str, pyspark.ml.param.Param[Any]]) -> bool\n |      Checks whether a param is explicitly set by user.\n |  \n |  set(self, param: pyspark.ml.param.Param, value: Any) -> None\n |      Sets a parameter in the embedded param map.\n |  \n |  ----------------------------------------------------------------------\n |  Readonly properties inherited from pyspark.ml.param.Params:\n |  \n |  params\n |      Returns all params ordered by name. The default implementation\n |      uses :py:func:`dir` to get all attributes of type\n |      :py:class:`Param`.\n |  \n |  ----------------------------------------------------------------------\n |  Methods inherited from pyspark.ml.util.Identifiable:\n |  \n |  __repr__(self) -> str\n |      Return repr(self).\n |  \n |  ----------------------------------------------------------------------\n |  Methods inherited from pyspark.ml.util.JavaMLWritable:\n |  \n |  write(self) -> pyspark.ml.util.JavaMLWriter\n |      Returns an MLWriter instance for this ML instance.\n |  \n |  ----------------------------------------------------------------------\n |  Methods inherited from pyspark.ml.util.MLWritable:\n |  \n |  save(self, path: str) -> None\n |      Save this ML instance to the given path, a shortcut of 'write().save(path)'.\n |  \n |  ----------------------------------------------------------------------\n |  Class methods inherited from pyspark.ml.util.JavaMLReadable:\n |  \n |  read() -> pyspark.ml.util.JavaMLReader[~RL] from abc.ABCMeta\n |      Returns an MLReader instance for this class.\n |  \n |  ----------------------------------------------------------------------\n |  Class methods inherited from pyspark.ml.util.MLReadable:\n |  \n |  load(path: str) -> ~RL from abc.ABCMeta\n |      Reads an ML instance from the input path, a shortcut of `read().load(path)`.\n |  \n |  ----------------------------------------------------------------------\n |  Class methods inherited from typing.Generic:\n |  \n |  __class_getitem__(params) from abc.ABCMeta\n |  \n |  __init_subclass__(*args, **kwargs) from abc.ABCMeta\n |      This method is called when a class is subclassed.\n |      \n |      The default implementation does nothing. It may be\n |      overridden to extend subclasses.\n\n"]}],"execution_count":0},{"cell_type":"code","source":["lr = LinearRegression(labelCol='demand')"],"metadata":{"application/vnd.databricks.v1+cell":{"showTitle":false,"cellMetadata":{},"nuid":"27ea136e-4a31-45d5-be97-8ed7e8ca89ee","inputWidgets":{},"title":""}},"outputs":[],"execution_count":0},{"cell_type":"code","source":["lr.explainParam(\"elasticNetParam\")"],"metadata":{"application/vnd.databricks.v1+cell":{"showTitle":false,"cellMetadata":{},"nuid":"14532771-f257-49fb-bd18-44e80afef657","inputWidgets":{},"title":""}},"outputs":[{"output_type":"stream","output_type":"stream","name":"stdout","text":["Out[31]: 'elasticNetParam: the ElasticNet mixing parameter, in range [0, 1]. For alpha = 0, the penalty is an L2 penalty. For alpha = 1, it is an L1 penalty. (default: 0.0)'"]}],"execution_count":0},{"cell_type":"code","source":["lr.explainParams()"],"metadata":{"application/vnd.databricks.v1+cell":{"showTitle":false,"cellMetadata":{},"nuid":"aaf81c80-6ffa-4104-982f-39715a159de7","inputWidgets":{},"title":""}},"outputs":[{"output_type":"stream","output_type":"stream","name":"stdout","text":["Out[32]: 'aggregationDepth: suggested depth for treeAggregate (>= 2). (default: 2)\\nelasticNetParam: the ElasticNet mixing parameter, in range [0, 1]. For alpha = 0, the penalty is an L2 penalty. For alpha = 1, it is an L1 penalty. (default: 0.0)\\nepsilon: The shape parameter to control the amount of robustness. Must be > 1.0. Only valid when loss is huber (default: 1.35)\\nfeaturesCol: features column name. (default: features)\\nfitIntercept: whether to fit an intercept term. (default: True)\\nlabelCol: label column name. (default: label, current: demand)\\nloss: The loss function to be optimized. Supported options: squaredError, huber. (default: squaredError)\\nmaxBlockSizeInMB: maximum memory in MB for stacking input data into blocks. Data is stacked within partitions. If more than remaining data size in a partition then it is adjusted to the data size. Default 0.0 represents choosing optimal value, depends on specific algorithm. Must be >= 0. (default: 0.0)\\nmaxIter: max number of iterations (>= 0). (default: 100)\\npredictionCol: prediction column name. (default: prediction)\\nregParam: regularization parameter (>= 0). (default: 0.0)\\nsolver: The solver algorithm for optimization. Supported options: auto, normal, l-bfgs. (default: auto)\\nstandardization: whether to standardize the training features before fitting the model. (default: True)\\ntol: the convergence tolerance for iterative algorithms (>= 0). (default: 1e-06)\\nweightCol: weight column name. If this is not set or empty, we treat all instance weights as 1.0. (undefined)'"]}],"execution_count":0},{"cell_type":"code","source":["trainData.cache()"],"metadata":{"application/vnd.databricks.v1+cell":{"showTitle":false,"cellMetadata":{},"nuid":"cd92d498-2212-4499-b05a-85978e78b53b","inputWidgets":{},"title":""}},"outputs":[{"output_type":"stream","output_type":"stream","name":"stdout","text":["Out[33]: DataFrame[features: vector, demand: int]"]}],"execution_count":0},{"cell_type":"code","source":["testData.cache()"],"metadata":{"application/vnd.databricks.v1+cell":{"showTitle":false,"cellMetadata":{},"nuid":"4f20d1e7-499c-46f0-bed0-6a4cee425467","inputWidgets":{},"title":""}},"outputs":[{"output_type":"stream","output_type":"stream","name":"stdout","text":["Out[34]: DataFrame[features: vector, demand: int]"]}],"execution_count":0},{"cell_type":"code","source":["lrModel = lr.fit(trainData)"],"metadata":{"application/vnd.databricks.v1+cell":{"showTitle":false,"cellMetadata":{},"nuid":"1ddc5de2-908b-4269-872b-bf93a0693b8b","inputWidgets":{},"title":""}},"outputs":[],"execution_count":0},{"cell_type":"code","source":["summary = lrModel.summary"],"metadata":{"application/vnd.databricks.v1+cell":{"showTitle":false,"cellMetadata":{},"nuid":"fb756468-27b0-426f-9bad-07482f422246","inputWidgets":{},"title":""}},"outputs":[],"execution_count":0},{"cell_type":"code","source":["summary.explainedVariance"],"metadata":{"application/vnd.databricks.v1+cell":{"showTitle":false,"cellMetadata":{},"nuid":"f578b41e-3755-415c-aca7-472625c0054c","inputWidgets":{},"title":""}},"outputs":[{"output_type":"stream","output_type":"stream","name":"stdout","text":["Out[37]: 13051.816703181148"]}],"execution_count":0},{"cell_type":"code","source":["summary.meanAbsoluteError"],"metadata":{"application/vnd.databricks.v1+cell":{"showTitle":false,"cellMetadata":{},"nuid":"d6bd8be3-8dfc-4e6f-acd4-8ee3939fb0d5","inputWidgets":{},"title":""}},"outputs":[{"output_type":"stream","output_type":"stream","name":"stdout","text":["Out[38]: 105.83726673347506"]}],"execution_count":0},{"cell_type":"code","source":["data.select('demand').describe().show()\n"],"metadata":{"application/vnd.databricks.v1+cell":{"showTitle":false,"cellMetadata":{},"nuid":"11abe0d9-c395-44d8-b7b4-17861e6d31dd","inputWidgets":{},"title":""}},"outputs":[{"output_type":"stream","output_type":"stream","name":"stdout","text":["+-------+------------------+\n|summary|            demand|\n+-------+------------------+\n|  count|             17379|\n|   mean|189.46308763450142|\n| stddev| 181.3875990918646|\n|    min|                 1|\n|    max|               977|\n+-------+------------------+\n\n"]}],"execution_count":0},{"cell_type":"code","source":["summary.r2"],"metadata":{"application/vnd.databricks.v1+cell":{"showTitle":false,"cellMetadata":{},"nuid":"a280aa4e-feb6-4319-b77e-967bdaae91dd","inputWidgets":{},"title":""}},"outputs":[{"output_type":"stream","output_type":"stream","name":"stdout","text":["Out[40]: 0.3936499389017416"]}],"execution_count":0},{"cell_type":"code","source":["summary.predictions.show(n=20, truncate = False)"],"metadata":{"application/vnd.databricks.v1+cell":{"showTitle":false,"cellMetadata":{},"nuid":"80f6defb-4d4c-471c-a13b-cbf518f1b811","inputWidgets":{},"title":""}},"outputs":[{"output_type":"stream","output_type":"stream","name":"stdout","text":["+-----------------------------------------------+------+-------------------+\n|features                                       |demand|prediction         |\n+-----------------------------------------------+------+-------------------+\n|(11,[0,1,2,6,7,8],[1.0,1.0,12.0,2.0,0.24,0.7]) |26.0  |7.767053255798576  |\n|(11,[0,1,2,6,7,8],[2.0,1.0,3.0,1.0,0.58,0.68]) |156.0 |141.2224272738397  |\n|(11,[0,1,2,6,7,8],[2.0,1.0,5.0,1.0,0.6,0.83])  |153.0 |116.46015625278602 |\n|(11,[0,1,2,6,7,8],[3.0,1.0,6.0,1.0,0.64,0.83]) |116.0 |148.66718942759502 |\n|(11,[0,1,2,6,7,8],[4.0,1.0,12.0,1.0,0.26,0.81])|108.0 |61.38349984462701  |\n|(11,[0,1,2,6,7,8],[4.0,1.0,12.0,1.0,0.3,0.7])  |94.0  |94.32977790713895  |\n|(11,[0,2,3,6,7,8],[1.0,1.0,1.0,1.0,0.22,0.8])  |40.0  |-79.12374036311121 |\n|(11,[0,2,3,6,7,8],[1.0,1.0,2.0,1.0,0.22,0.8])  |32.0  |-71.4037726808723  |\n|(11,[0,2,3,6,7,8],[1.0,1.0,2.0,2.0,0.18,0.55]) |16.0  |-39.38474260181509 |\n|(11,[0,2,3,6,7,8],[1.0,1.0,3.0,1.0,0.24,0.75]) |13.0  |-48.18706218079777 |\n|(11,[0,2,3,6,7,8],[1.0,1.0,3.0,2.0,0.16,0.59]) |8.0   |-45.208725310571026|\n|(11,[0,2,3,6,7,8],[1.0,1.0,4.0,2.0,0.16,0.59]) |5.0   |-37.48875762833211 |\n|(11,[0,2,3,6,7,8],[1.0,1.0,5.0,1.0,0.16,0.59]) |1.0   |-24.43357072139619 |\n|(11,[0,2,3,6,7,8],[1.0,1.0,7.0,1.0,0.14,0.63]) |10.0  |-22.537585747913237|\n|(11,[0,2,3,6,7,8],[1.0,1.0,7.0,1.0,0.2,0.86])  |3.0   |-50.25346951435398 |\n|(11,[0,2,3,6,7,8],[1.0,1.0,9.0,1.0,0.32,0.76]) |14.0  |19.111074220322937 |\n|(11,[0,2,3,6,7,8],[1.0,1.0,17.0,1.0,0.12,0.28])|67.0  |117.27704533026935 |\n|(11,[0,2,3,6,7,8],[1.0,1.0,17.0,1.0,0.24,0.6]) |91.0  |89.18437177315798  |\n|(11,[0,2,3,6,7,8],[1.0,1.0,22.0,1.0,0.06,0.49])|30.0  |97.66990072691283  |\n|(11,[0,2,3,6,7,8],[1.0,2.0,3.0,1.0,0.12,0.8])  |10.0  |-92.94929106783064 |\n+-----------------------------------------------+------+-------------------+\nonly showing top 20 rows\n\n"]}],"execution_count":0},{"cell_type":"code","source":["print (\"explainedVariance={}\".format(summary.explainedVariance))\nprint (\"meanAbsoluteError=%g\" %summary.meanAbsoluteError)"],"metadata":{"application/vnd.databricks.v1+cell":{"showTitle":false,"cellMetadata":{},"nuid":"85bc2103-3d5c-4f29-9017-2c3880c172fa","inputWidgets":{},"title":""}},"outputs":[{"output_type":"stream","output_type":"stream","name":"stdout","text":["explainedVariance=13051.816703181148\nmeanAbsoluteError=105.837\n"]}],"execution_count":0},{"cell_type":"code","source":["testResults = lrModel.evaluate(testData)"],"metadata":{"application/vnd.databricks.v1+cell":{"showTitle":false,"cellMetadata":{},"nuid":"c89c9898-b59e-4a11-9e94-d5748bbfd589","inputWidgets":{},"title":""}},"outputs":[],"execution_count":0},{"cell_type":"code","source":["testResults.residuals.show(n=10)"],"metadata":{"application/vnd.databricks.v1+cell":{"showTitle":false,"cellMetadata":{},"nuid":"72c03ed6-7cf7-452f-a4af-22fee6b74677","inputWidgets":{},"title":""}},"outputs":[{"output_type":"stream","output_type":"stream","name":"stdout","text":["+------------------+\n|         residuals|\n+------------------+\n|  -67.288580342215|\n| 41.46709449855885|\n| 42.52390195191663|\n|17.587223769603153|\n|22.737933753835335|\n| 1.162890034208516|\n|138.37320030972083|\n|109.93647806643759|\n| 9.069636066139505|\n| 84.09203013125111|\n+------------------+\nonly showing top 10 rows\n\n"]}],"execution_count":0},{"cell_type":"code","source":["testResults.residuals.groupBy().avg().show() "],"metadata":{"application/vnd.databricks.v1+cell":{"showTitle":false,"cellMetadata":{},"nuid":"398f6d4b-8434-41a6-8f94-a82ac459190d","inputWidgets":{},"title":""}},"outputs":[{"output_type":"stream","output_type":"stream","name":"stdout","text":["+-------------------+\n|     avg(residuals)|\n+-------------------+\n|0.08950312008645038|\n+-------------------+\n\n"]}],"execution_count":0},{"cell_type":"markdown","source":["- The average of the residuals does not reflect the reality as the residuals can be negative\n- The mean absolute error is the average of the absolute values of the residuals"],"metadata":{"application/vnd.databricks.v1+cell":{"showTitle":false,"cellMetadata":{},"nuid":"c98aa7aa-493d-4348-be9e-a71097df62e2","inputWidgets":{},"title":""}}},{"cell_type":"code","source":["from pyspark.sql.functions import abs\ndf= testResults.residuals\ndf.select(abs(df.residuals)).groupBy().avg().show()"],"metadata":{"application/vnd.databricks.v1+cell":{"showTitle":false,"cellMetadata":{},"nuid":"d8fca726-1be0-4a04-8a23-ecf350a2c6ba","inputWidgets":{},"title":""}},"outputs":[{"output_type":"stream","output_type":"stream","name":"stdout","text":["+-------------------+\n|avg(abs(residuals))|\n+-------------------+\n| 106.67420837950966|\n+-------------------+\n\n"]}],"execution_count":0},{"cell_type":"code","source":["print (\"r2=%g\"%testResults.r2)   # my model explains x % of the variance of the data\nprint (\"rootMeanSquaredError=%g\"%testResults.rootMeanSquaredError)"],"metadata":{"application/vnd.databricks.v1+cell":{"showTitle":false,"cellMetadata":{},"nuid":"1d2d4e57-0c14-4463-b345-e60cc1a4b63a","inputWidgets":{},"title":""}},"outputs":[{"output_type":"stream","output_type":"stream","name":"stdout","text":["r2=0.372493\nrootMeanSquaredError=142.375\n"]}],"execution_count":0},{"cell_type":"code","source":["print (\"meanAbsoluteError=%g\"%testResults.meanAbsoluteError)"],"metadata":{"application/vnd.databricks.v1+cell":{"showTitle":false,"cellMetadata":{},"nuid":"891a03d7-4b25-4a55-9ca5-d509464333e7","inputWidgets":{},"title":""}},"outputs":[{"output_type":"stream","output_type":"stream","name":"stdout","text":["meanAbsoluteError=106.674\n"]}],"execution_count":0},{"cell_type":"markdown","source":["## Underfitting !\n- decrease regularization parameter? \n- Add more features? Feature Engineering?\n- Polynomial Regression? other algorithms? Trees? \n\n### Anyway let's get some insights from our data !"],"metadata":{"application/vnd.databricks.v1+cell":{"showTitle":false,"cellMetadata":{},"nuid":"1342b734-0f03-41ba-b6f5-38d6a3a17773","inputWidgets":{},"title":""}}},{"cell_type":"code","source":["data.printSchema()"],"metadata":{"scrolled":true,"application/vnd.databricks.v1+cell":{"showTitle":false,"cellMetadata":{},"nuid":"822e4e7b-202a-4b2c-b5fc-0373fac31859","inputWidgets":{},"title":""}},"outputs":[{"output_type":"stream","output_type":"stream","name":"stdout","text":["root\n |-- season: integer (nullable = true)\n |-- yr: integer (nullable = true)\n |-- mnth: integer (nullable = true)\n |-- hr: integer (nullable = true)\n |-- holiday: integer (nullable = true)\n |-- workingday: integer (nullable = true)\n |-- weathersit: integer (nullable = true)\n |-- temp: double (nullable = true)\n |-- hum: double (nullable = true)\n |-- windspeed: double (nullable = true)\n |-- dayOfWeek: string (nullable = true)\n |-- days: integer (nullable = true)\n |-- demand: integer (nullable = true)\n |-- day_cat: double (nullable = false)\n |-- features: vector (nullable = true)\n\n"]}],"execution_count":0},{"cell_type":"code","source":["insights = lrModel.evaluate(data)"],"metadata":{"application/vnd.databricks.v1+cell":{"showTitle":false,"cellMetadata":{},"nuid":"190a7230-ebbd-41a8-b069-f4396c475618","inputWidgets":{},"title":""}},"outputs":[],"execution_count":0},{"cell_type":"code","source":["pred = insights.predictions"],"metadata":{"application/vnd.databricks.v1+cell":{"showTitle":false,"cellMetadata":{},"nuid":"a0007bce-8128-4a63-8f0a-a58d6587158e","inputWidgets":{},"title":""}},"outputs":[],"execution_count":0},{"cell_type":"code","source":["pred.take(1)"],"metadata":{"application/vnd.databricks.v1+cell":{"showTitle":false,"cellMetadata":{},"nuid":"ccef730b-1789-43a7-92b8-22f75459e8be","inputWidgets":{},"title":""}},"outputs":[{"output_type":"stream","output_type":"stream","name":"stdout","text":["Out[52]: [Row(season=1, yr=0, mnth=1, hr=0, holiday=0, workingday=0, weathersit=1, temp=0.24, hum=0.81, windspeed=0.0, dayOfWeek='Sat', days=0, demand=16, day_cat=0.0, features=SparseVector(11, {0: 1.0, 2: 1.0, 6: 1.0, 7: 0.24, 8: 0.81}), prediction=-83.06371978855887)]"]}],"execution_count":0},{"cell_type":"code","source":["pred_res = pred.withColumn('res_abs', abs(pred.prediction-pred.demand))"],"metadata":{"application/vnd.databricks.v1+cell":{"showTitle":false,"cellMetadata":{},"nuid":"0b7ef2af-8e12-4f2c-ad6a-e71f877265c1","inputWidgets":{},"title":""}},"outputs":[],"execution_count":0},{"cell_type":"code","source":[""],"metadata":{"application/vnd.databricks.v1+cell":{"showTitle":false,"cellMetadata":{},"nuid":"e3e5608c-e14b-4ea3-9ab3-4bcca793d131","inputWidgets":{},"title":""}},"outputs":[],"execution_count":0},{"cell_type":"code","source":["#for item in pred_res.take(1)[0]: \n#  print (item)\n"],"metadata":{"application/vnd.databricks.v1+cell":{"showTitle":false,"cellMetadata":{},"nuid":"0d8af30e-81bc-428c-b833-f748039fe87c","inputWidgets":{},"title":""}},"outputs":[],"execution_count":0},{"cell_type":"code","source":["pred_res.take(1)"],"metadata":{"application/vnd.databricks.v1+cell":{"showTitle":false,"cellMetadata":{},"nuid":"9cb83e81-b9d4-4937-909e-665090c82864","inputWidgets":{},"title":""}},"outputs":[{"output_type":"stream","output_type":"stream","name":"stdout","text":["Out[55]: [Row(season=1, yr=0, mnth=1, hr=0, holiday=0, workingday=0, weathersit=1, temp=0.24, hum=0.81, windspeed=0.0, dayOfWeek='Sat', days=0, demand=16, day_cat=0.0, features=SparseVector(11, {0: 1.0, 2: 1.0, 6: 1.0, 7: 0.24, 8: 0.81}), prediction=-83.06371978855887, res_abs=99.06371978855887)]"]}],"execution_count":0},{"cell_type":"code","source":["\nfrom pyspark.sql.functions import avg, stddev, format_number"],"metadata":{"application/vnd.databricks.v1+cell":{"showTitle":false,"cellMetadata":{},"nuid":"12953e19-4fb7-4b31-8ffa-a7a5aa6dd4a1","inputWidgets":{},"title":""}},"outputs":[],"execution_count":0},{"cell_type":"code","source":["from pyspark.sql.functions import format_number\npred_res.groupBy('hr').agg(format_number(avg('res_abs'), 2).alias('avg_abs_residual'), \n                           format_number(avg('demand'), 2).alias('avg_demand'), \n                           format_number(stddev('prediction'), 2).alias('stddev_prediction'), \n                           format_number(stddev('demand'), 2).alias('stddev_demand')\n                          ).sort('hr').show()"],"metadata":{"application/vnd.databricks.v1+cell":{"showTitle":false,"cellMetadata":{},"nuid":"01c4ab04-71d5-4d62-8362-8b04a81addc2","inputWidgets":{},"title":""}},"outputs":[{"output_type":"stream","output_type":"stream","name":"stdout","text":["+---+----------------+----------+-----------------+-------------+\n| hr|avg_abs_residual|avg_demand|stddev_prediction|stddev_demand|\n+---+----------------+----------+-----------------+-------------+\n|  0|           60.43|     53.90|            78.42|        42.31|\n|  1|           71.89|     33.38|            77.35|        33.54|\n|  2|           79.65|     22.87|            75.96|        26.58|\n|  3|           89.61|     11.73|            73.66|        13.24|\n|  4|           96.52|      6.35|            72.70|         4.14|\n|  5|           87.33|     19.89|            73.64|        13.20|\n|  6|           53.73|     76.04|            74.43|        55.08|\n|  7|          143.15|    212.06|            77.61|       161.44|\n|  8|          249.31|    359.01|            82.39|       235.19|\n|  9|           77.27|    219.31|            85.06|        93.70|\n| 10|           69.87|    173.67|            88.53|       102.21|\n| 11|           80.61|    208.14|            90.11|       127.50|\n| 12|           83.24|    253.32|            91.63|       145.08|\n| 13|           89.08|    253.66|            92.08|       148.11|\n| 14|           99.30|    240.95|            93.18|       147.27|\n| 15|           94.91|    251.23|            93.75|       144.63|\n| 16|           80.99|    311.98|            93.89|       148.68|\n| 17|          207.21|    461.45|            94.00|       232.66|\n| 18|          179.91|    425.51|            91.59|       224.64|\n| 19|           89.94|    311.52|            88.67|       161.05|\n+---+----------------+----------+-----------------+-------------+\nonly showing top 20 rows\n\n"]}],"execution_count":0},{"cell_type":"code","source":[""],"metadata":{"application/vnd.databricks.v1+cell":{"showTitle":false,"cellMetadata":{},"nuid":"6b77eea7-e8d9-4d3d-b4e0-26103560c602","inputWidgets":{},"title":""}},"outputs":[],"execution_count":0},{"cell_type":"code","source":[""],"metadata":{"application/vnd.databricks.v1+cell":{"showTitle":false,"cellMetadata":{},"nuid":"d5f89892-19fa-4e39-95c2-6728ead85a54","inputWidgets":{},"title":""}},"outputs":[],"execution_count":0},{"cell_type":"code","source":[""],"metadata":{"application/vnd.databricks.v1+cell":{"showTitle":false,"cellMetadata":{},"nuid":"45d825d0-7ad2-4b1a-b0d8-27a5d38b29a3","inputWidgets":{},"title":""}},"outputs":[],"execution_count":0},{"cell_type":"code","source":[""],"metadata":{"application/vnd.databricks.v1+cell":{"showTitle":false,"cellMetadata":{},"nuid":"f937d512-7c4a-47ce-acda-ef80a63d7737","inputWidgets":{},"title":""}},"outputs":[],"execution_count":0}],"metadata":{"language_info":{"mimetype":"text/x-python","name":"python","pygments_lexer":"ipython3","codemirror_mode":{"name":"ipython","version":3},"version":"3.5.2","nbconvert_exporter":"python","file_extension":".py"},"name":"LinearRegression","notebookId":1426360990457188,"kernelspec":{"display_name":"Python 3","language":"python","name":"python3"},"application/vnd.databricks.v1+notebook":{"notebookName":"LinearRegressionBikeRental-starter","dashboards":[],"notebookMetadata":{"pythonIndentUnit":2},"language":"python","widgets":{}}},"nbformat":4,"nbformat_minor":0}
